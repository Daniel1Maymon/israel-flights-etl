services:
  postgres:
    container_name: postgres_airflow
    image: postgres:16.3
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=airflow
      - POSTGRES_PORT=5432
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: airflow-init
    container_name: airflow_init
    depends_on:
      - postgres
    external_links:
      - postgres_flights:postgres_flights
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
      - PYTHONPATH=/opt/airflow
      # AWS S3 Connection
      - AIRFLOW__CONN__AWS_S3=aws://${AWS_ACCESS_KEY_ID}:${AWS_SECRET_ACCESS_KEY}@s3.${AWS_DEFAULT_REGION}.amazonaws.com
      # PostgreSQL Connection for Airflow metadata
      - AIRFLOW__CONN__POSTGRES_AIRFLOW=postgres://postgres:postgres@postgres:5432/airflow
      # PostgreSQL Connection for flights data
      - AIRFLOW__CONN__POSTGRES_FLIGHTS=postgres://${POSTGRES_FLIGHTS_USER}:${POSTGRES_FLIGHTS_PASSWORD}@postgres_flights:5432/flights_db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl
      - ./utils:/opt/airflow/utils
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./config:/opt/airflow/config
    entrypoint: /bin/bash
    command:
      - -c
      - |
        until pg_isready -h postgres -p 5432 -U postgres; do
          echo "Waiting for Postgres..."
          sleep 2
        done
        echo "Postgres is ready."

        airflow db migrate

        airflow users list | grep -q "airflow" || \
        airflow users create \
          --role Admin \
          --username airflow \
          --password airflow \
          --email airflow@airflow.com \
          --firstname airflow \
          --lastname airflow

        echo "Airflow initialization completed."
    restart: "no"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    external_links:
      - postgres_flights:postgres_flights
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=True
      - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl
      - ./utils:/opt/airflow/utils
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./config:/opt/airflow/config
    ports:
      - 8082:8080
    command: airflow webserver
    restart: "no"

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    external_links:
      - postgres_flights:postgres_flights
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
      - PYTHONPATH=/opt/airflow
      # AWS S3 Connection
      - AIRFLOW__CONN__AWS_S3=aws://${AWS_ACCESS_KEY_ID}:${AWS_SECRET_ACCESS_KEY}@s3.${AWS_DEFAULT_REGION}.amazonaws.com
      # PostgreSQL Connection for Airflow metadata
      - AIRFLOW__CONN__POSTGRES_AIRFLOW=postgres://postgres:postgres@postgres:5432/airflow
      # PostgreSQL Connection for flights data
      - AIRFLOW__CONN__POSTGRES_FLIGHTS=postgres://${POSTGRES_FLIGHTS_USER}:${POSTGRES_FLIGHTS_PASSWORD}@postgres_flights:5432/flights_db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl
      - ./utils:/opt/airflow/utils
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./config:/opt/airflow/config
    command: airflow scheduler
    restart: "no"

volumes:
  postgres_data:
  postgres_flights_data:
  israel-flights-etl_postgres_flights_data:
    external: true
